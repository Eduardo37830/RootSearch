# Configuraci√≥n del Servidor de Transcripci√≥n Local

## Problema
```
‚ùå Error HTTP: 400 - Bad Request
üìã Response data: {
  detail: '[WinError 2] El sistema no puede encontrar el archivo especificado'
}
```

## Causa
El backend de NestJS intenta usar un servidor Python local en `http://127.0.0.1:8000` para transcribir audio, pero:

1. **El servidor Python no est√° ejecut√°ndose**, O
2. **El servidor Python no tiene acceso a la carpeta `backend/uploads/`**, O
3. **Deber√≠as usar el adaptador de OpenAI en lugar del servidor local**

## Soluci√≥n 1: Usar OpenAI (Recomendado) ‚úÖ

Es m√°s f√°cil y no requiere servidor Python adicional.

### Configurar el Backend para usar OpenAI

1. **Edita el archivo `.env` del backend:**

```env
# Transcription Adapter: 'openai' o 'local'
TRANSCRIPTION_ADAPTER=openai

# OpenAI API Key
OPENAI_API_KEY=tu_api_key_aqui
```

2. **Reinicia el backend:**

```powershell
cd C:\universidad\Ingenieria_software_3\RootSearch\backend
npm run start:dev
```

El backend ahora usar√° la API de OpenAI Whisper para transcribir.

## Soluci√≥n 2: Configurar Servidor Python Local

Si prefieres usar transcripci√≥n local (gratis pero requiere configuraci√≥n):

### Paso 1: Crear el servidor Python

Crea un archivo `transcription-server/main.py`:

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import whisper
import os
from fastapi.middleware.cors import CORSMiddleware

app = FastAPI()

# Permitir CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Cargar modelo de Whisper (una sola vez al iniciar)
print("Cargando modelo Whisper...")
model = whisper.load_model("base")  # Puedes usar: tiny, base, small, medium, large
print("‚úÖ Modelo cargado")

class TranscriptionRequest(BaseModel):
    file_path: str
    language: str = "es"

@app.post("/api/transcribe")
async def transcribe_audio(request: TranscriptionRequest):
    try:
        file_path = request.file_path
        
        # Verificar que el archivo existe
        if not os.path.exists(file_path):
            raise HTTPException(
                status_code=400,
                detail=f"Archivo no encontrado: {file_path}"
            )
        
        print(f"üìÇ Transcribiendo: {file_path}")
        
        # Transcribir
        result = model.transcribe(
            file_path,
            language=request.language,
            fp16=False  # Usar CPU
        )
        
        print(f"‚úÖ Transcripci√≥n completada")
        
        return {
            "text": result["text"],
            "language": result["language"]
        }
        
    except Exception as e:
        print(f"‚ùå Error: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
async def root():
    return {"status": "ok", "message": "Servidor de transcripci√≥n activo"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="127.0.0.1", port=8000)
```

### Paso 2: Instalar dependencias Python

```powershell
# Crear entorno virtual
cd C:\universidad\Ingenieria_software_3\RootSearch
mkdir transcription-server
cd transcription-server

python -m venv venv
.\venv\Scripts\Activate.ps1

# Instalar dependencias
pip install fastapi uvicorn openai-whisper torch
```

### Paso 3: Iniciar el servidor Python

```powershell
cd C:\universidad\Ingenieria_software_3\RootSearch\transcription-server
.\venv\Scripts\Activate.ps1
python main.py
```

Deber√≠as ver:
```
Cargando modelo Whisper...
‚úÖ Modelo cargado
INFO:     Uvicorn running on http://127.0.0.1:8000
```

### Paso 4: Configurar el backend

En el archivo `.env` del backend:

```env
TRANSCRIPTION_ADAPTER=local
LOCAL_TRANSCRIPTION_ENDPOINT=http://127.0.0.1:8000/api/transcribe
```

## Soluci√≥n 3: Verificar Permisos de Carpeta

Si el servidor Python est√° corriendo pero no encuentra los archivos:

1. **Verifica que la carpeta uploads existe:**

```powershell
ls C:\universidad\Ingenieria_software_3\RootSearch\backend\uploads
```

2. **Dale permisos completos a la carpeta:**

```powershell
icacls "C:\universidad\Ingenieria_software_3\RootSearch\backend\uploads" /grant Everyone:F
```

## Comparaci√≥n de Opciones

| Caracter√≠stica | OpenAI (Recomendado) | Servidor Local |
|----------------|----------------------|----------------|
| Configuraci√≥n | ‚úÖ F√°cil (solo API Key) | ‚ö†Ô∏è Requiere Python + Whisper |
| Costo | üí∞ $0.006/minuto | üÜì Gratis |
| Velocidad | ‚ö° Muy r√°pido | üêå Lento (depende de tu CPU/GPU) |
| Calidad | üåü Excelente | üëç Buena (modelo base) |
| Requisitos | Internet | CPU/GPU potente |
| Idiomas | 50+ idiomas | 50+ idiomas |

## Verificaci√≥n

### Probar OpenAI:
```powershell
curl -X POST http://localhost:3001/materials/upload-audio `
  -H "Authorization: Bearer tu_token" `
  -F "file=@audio.ogg" `
  -F "courseId=123"
```

### Probar servidor local:
```powershell
# Verificar que est√° activo
curl http://127.0.0.1:8000/
```

## Recomendaci√≥n Final

**Usa OpenAI** (Soluci√≥n 1) porque:
- Es m√°s r√°pido
- No requiere configuraci√≥n adicional
- La calidad es excelente
- El costo es muy bajo ($0.006 por minuto)

Solo usa el servidor local si:
- No tienes presupuesto para APIs
- Necesitas procesar muchas horas de audio
- Tienes una GPU potente
